{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code block is responsible for training and evaluating a Vanilla RNN for EEG signal classification and measuring test accuracy."
      ],
      "metadata": {
        "id": "FN59tcwmbhDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Vanilla RNN model\n",
        "class VanillaRNN(nn.Module):\n",
        "    def __init__(self, input_size=22, hidden_size=64, output_size=4, num_layers=2):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, nonlinearity='tanh')\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out[:, -1, :])  # Use the last time step's output for classification\n",
        "        return out\n",
        "\n",
        "# Generate Synthetic EEG Data\n",
        "def generate_synthetic_data(num_samples=1000, seq_length=20, input_size=22, num_classes=4):\n",
        "    X = np.random.rand(num_samples, seq_length, input_size)\n",
        "    y = np.random.randint(0, num_classes, num_samples)\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Prepare dataset\n",
        "X_train_valid, y_train_valid = generate_synthetic_data(num_samples=800)\n",
        "X_test, y_test = generate_synthetic_data(num_samples=200)\n",
        "\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(X_train_valid, y_train_valid)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Training function\n",
        "def train_rnn(num_epochs=40, learning_rate=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = VanillaRNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "        train_accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in test_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_X)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "    test_accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy:.2f}%')\n",
        "    return model\n",
        "\n",
        "# Train the Vanilla RNN\n",
        "rnn_model = train_rnn()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZeRPkSeKP2t",
        "outputId": "d88df93e-4e62-4425-bd69-e830e8406af3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40], Loss: 1.3996, Train Accuracy: 24.12%\n",
            "Epoch [2/40], Loss: 1.3820, Train Accuracy: 26.00%\n",
            "Epoch [3/40], Loss: 1.3676, Train Accuracy: 34.25%\n",
            "Epoch [4/40], Loss: 1.3491, Train Accuracy: 35.50%\n",
            "Epoch [5/40], Loss: 1.3222, Train Accuracy: 39.25%\n",
            "Epoch [6/40], Loss: 1.2966, Train Accuracy: 39.75%\n",
            "Epoch [7/40], Loss: 1.2611, Train Accuracy: 42.12%\n",
            "Epoch [8/40], Loss: 1.2324, Train Accuracy: 47.12%\n",
            "Epoch [9/40], Loss: 1.2023, Train Accuracy: 45.75%\n",
            "Epoch [10/40], Loss: 1.1763, Train Accuracy: 50.50%\n",
            "Epoch [11/40], Loss: 1.1474, Train Accuracy: 50.62%\n",
            "Epoch [12/40], Loss: 1.1338, Train Accuracy: 49.62%\n",
            "Epoch [13/40], Loss: 1.1102, Train Accuracy: 52.12%\n",
            "Epoch [14/40], Loss: 1.0969, Train Accuracy: 53.38%\n",
            "Epoch [15/40], Loss: 1.0736, Train Accuracy: 55.00%\n",
            "Epoch [16/40], Loss: 1.0448, Train Accuracy: 55.00%\n",
            "Epoch [17/40], Loss: 1.0277, Train Accuracy: 57.62%\n",
            "Epoch [18/40], Loss: 1.0023, Train Accuracy: 57.88%\n",
            "Epoch [19/40], Loss: 0.9886, Train Accuracy: 58.88%\n",
            "Epoch [20/40], Loss: 0.9567, Train Accuracy: 61.88%\n",
            "Epoch [21/40], Loss: 0.9447, Train Accuracy: 62.12%\n",
            "Epoch [22/40], Loss: 0.9162, Train Accuracy: 62.75%\n",
            "Epoch [23/40], Loss: 0.8937, Train Accuracy: 63.88%\n",
            "Epoch [24/40], Loss: 0.8599, Train Accuracy: 66.00%\n",
            "Epoch [25/40], Loss: 0.8190, Train Accuracy: 66.75%\n",
            "Epoch [26/40], Loss: 0.7917, Train Accuracy: 68.62%\n",
            "Epoch [27/40], Loss: 0.7549, Train Accuracy: 70.00%\n",
            "Epoch [28/40], Loss: 0.7221, Train Accuracy: 72.75%\n",
            "Epoch [29/40], Loss: 0.6774, Train Accuracy: 74.50%\n",
            "Epoch [30/40], Loss: 0.6298, Train Accuracy: 75.88%\n",
            "Epoch [31/40], Loss: 0.5965, Train Accuracy: 78.25%\n",
            "Epoch [32/40], Loss: 0.5581, Train Accuracy: 79.75%\n",
            "Epoch [33/40], Loss: 0.5115, Train Accuracy: 81.88%\n",
            "Epoch [34/40], Loss: 0.4943, Train Accuracy: 82.00%\n",
            "Epoch [35/40], Loss: 0.4292, Train Accuracy: 86.00%\n",
            "Epoch [36/40], Loss: 0.3856, Train Accuracy: 87.62%\n",
            "Epoch [37/40], Loss: 0.3610, Train Accuracy: 88.62%\n",
            "Epoch [38/40], Loss: 0.2946, Train Accuracy: 92.75%\n",
            "Epoch [39/40], Loss: 0.2527, Train Accuracy: 93.50%\n",
            "Epoch [40/40], Loss: 0.2054, Train Accuracy: 96.12%\n",
            "Test Accuracy: 30.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code block extends the first by adding training time measurement."
      ],
      "metadata": {
        "id": "-EBNoRTZcYvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "# Define the Vanilla RNN model\n",
        "class VanillaRNN(nn.Module):\n",
        "    def __init__(self, input_size=22, hidden_size=64, output_size=4, num_layers=2):\n",
        "        super(VanillaRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, nonlinearity='tanh')\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.rnn(x, h0)\n",
        "        out = self.fc(out[:, -1, :])  # Use the last time stepâ€™s output for classification\n",
        "        return out\n",
        "\n",
        "# Generate Synthetic EEG Data\n",
        "def generate_synthetic_data(num_samples=1000, seq_length=20, input_size=22, num_classes=4):\n",
        "    X = np.random.rand(num_samples, seq_length, input_size)\n",
        "    y = np.random.randint(0, num_classes, num_samples)\n",
        "    return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "# Prepare dataset\n",
        "X_train_valid, y_train_valid = generate_synthetic_data(num_samples=800)\n",
        "X_test, y_test = generate_synthetic_data(num_samples=200)\n",
        "\n",
        "batch_size = 32\n",
        "train_dataset = TensorDataset(X_train_valid, y_train_valid)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Training function with time measurement\n",
        "def train_rnn(num_epochs=40, learning_rate=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = VanillaRNN().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Start time measurement\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == batch_y).sum().item()\n",
        "            total += batch_y.size(0)\n",
        "\n",
        "        train_accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "    # End time measurement\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Total Training Time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
        "\n",
        "    return model, training_time\n",
        "\n",
        "# Train the Vanilla RNN and measure training time\n",
        "rnn_model, training_time = train_rnn()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B23PzSX4OEs-",
        "outputId": "f19f2a89-aaaf-42bd-cfba-412f5a05d820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40], Loss: 1.3914, Train Accuracy: 25.12%\n",
            "Epoch [2/40], Loss: 1.3758, Train Accuracy: 30.25%\n",
            "Epoch [3/40], Loss: 1.3607, Train Accuracy: 31.88%\n",
            "Epoch [4/40], Loss: 1.3376, Train Accuracy: 35.12%\n",
            "Epoch [5/40], Loss: 1.3016, Train Accuracy: 39.88%\n",
            "Epoch [6/40], Loss: 1.2621, Train Accuracy: 45.00%\n",
            "Epoch [7/40], Loss: 1.2326, Train Accuracy: 42.75%\n",
            "Epoch [8/40], Loss: 1.1949, Train Accuracy: 48.12%\n",
            "Epoch [9/40], Loss: 1.1647, Train Accuracy: 48.75%\n",
            "Epoch [10/40], Loss: 1.1349, Train Accuracy: 51.50%\n",
            "Epoch [11/40], Loss: 1.1202, Train Accuracy: 51.62%\n",
            "Epoch [12/40], Loss: 1.1058, Train Accuracy: 51.88%\n",
            "Epoch [13/40], Loss: 1.0798, Train Accuracy: 55.00%\n",
            "Epoch [14/40], Loss: 1.0652, Train Accuracy: 55.12%\n",
            "Epoch [15/40], Loss: 1.0452, Train Accuracy: 56.75%\n",
            "Epoch [16/40], Loss: 1.0310, Train Accuracy: 59.50%\n",
            "Epoch [17/40], Loss: 1.0018, Train Accuracy: 60.25%\n",
            "Epoch [18/40], Loss: 0.9869, Train Accuracy: 61.12%\n",
            "Epoch [19/40], Loss: 0.9680, Train Accuracy: 61.88%\n",
            "Epoch [20/40], Loss: 0.9475, Train Accuracy: 62.12%\n",
            "Epoch [21/40], Loss: 0.9337, Train Accuracy: 63.25%\n",
            "Epoch [22/40], Loss: 0.8853, Train Accuracy: 66.75%\n",
            "Epoch [23/40], Loss: 0.8597, Train Accuracy: 67.88%\n",
            "Epoch [24/40], Loss: 0.8444, Train Accuracy: 67.00%\n",
            "Epoch [25/40], Loss: 0.8074, Train Accuracy: 70.75%\n",
            "Epoch [26/40], Loss: 0.8065, Train Accuracy: 70.62%\n",
            "Epoch [27/40], Loss: 0.7520, Train Accuracy: 72.25%\n",
            "Epoch [28/40], Loss: 0.6986, Train Accuracy: 76.00%\n",
            "Epoch [29/40], Loss: 0.6719, Train Accuracy: 76.50%\n",
            "Epoch [30/40], Loss: 0.6195, Train Accuracy: 79.12%\n",
            "Epoch [31/40], Loss: 0.5990, Train Accuracy: 78.62%\n",
            "Epoch [32/40], Loss: 0.5609, Train Accuracy: 82.38%\n",
            "Epoch [33/40], Loss: 0.5048, Train Accuracy: 85.75%\n",
            "Epoch [34/40], Loss: 0.4725, Train Accuracy: 86.38%\n",
            "Epoch [35/40], Loss: 0.4290, Train Accuracy: 87.88%\n",
            "Epoch [36/40], Loss: 0.4009, Train Accuracy: 88.88%\n",
            "Epoch [37/40], Loss: 0.3643, Train Accuracy: 88.62%\n",
            "Epoch [38/40], Loss: 0.3190, Train Accuracy: 91.12%\n",
            "Epoch [39/40], Loss: 0.2648, Train Accuracy: 94.62%\n",
            "Epoch [40/40], Loss: 0.2391, Train Accuracy: 95.25%\n",
            "Total Training Time: 9.13 seconds (0.15 minutes)\n"
          ]
        }
      ]
    }
  ]
}